% Here is an example of how to create a bibliography entry for an article using
% BibTeX. Generally you won't have to write these out yourself, because they are
% provided by most web sites that allow you to export citations. The string
% "clrsAlgorithms" is a citation key, and if you were citing the source in a
% document you would use \cite{clrsAlgorithms}.



% SOURCE 1 - Agent-Initiated Interaction in Phone UI Automation
@inproceedings{10.1145/3701716.3717526,
author = {Kahlon, Noam and Rom, Guy and Efros, Anatoly and Galgani, Filippo and Berkovitch, Omri and Caduri, Sapir and Bishop, William E. and Riva, Oriana and Dagan, Ido},
title = {Agent-Initiated Interaction in Phone UI Automation},
year = {2025},
isbn = {9798400713316},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701716.3717526},
doi = {10.1145/3701716.3717526},
abstract = {Phone automation agents aim to autonomously perform a given natural-language user request, such as scheduling appointments or booking a hotel. While much research effort has been devoted to screen understanding and action planning, complex tasks often necessitate user interaction for successful completion. Aligning the agent with the user's expectations is crucial for building trust and enabling personalized experiences. This requires the agent to proactively engage the user when necessary, avoiding actions that violate their preferences while refraining from unnecessary questions where a default action is expected. We argue that such subtle agent-initiated interaction with the user deserves focused research attention.To promote such research, this paper introduces a task formulation for detecting the need for user interaction and generating appropriate messages. We thoroughly define the task, including aspects like interaction timing and the scope of the agent's autonomy. Using this definition, we derived annotation guidelines and created a diverse dataset for the task, leveraging an existing UI automation dataset. We tested several text-based and multimodal baseline models for the task, finding that it is very challenging for current LLMs. We suggest that our task formulation, dataset, baseline models and analysis will be valuable for future UI automation research, specifically in addressing this crucial yet often overlooked aspect of agent-initiated interaction. This work provides a needed foundation to allow personalized agents to properly engage the user when needed, within the context of phone UI automation.},
booktitle = {Companion Proceedings of the ACM on Web Conference 2025},
pages = {2391-2400},
numpages = {10},
keywords = {conversational interaction, dataset, phone ui automation},
location = {Sydney NSW, Australia},
series = {WWW '25},
annote={}
}

% Source 2 - Requirements Are All You Need: The Final Frontier for End-User Software Engineering
@article{10.1145/3708524,
author = {Robinson, Diana and Cabrera, Christian and Gordon, Andrew D. and Lawrence, Neil D. and Mennen, Lars},
title = {Requirements Are All You Need: The Final Frontier for End-User Software Engineering},
year = {2025},
month= {June},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708524},
doi = {10.1145/3708524},
abstract = {What if end-users could own the software development lifecycle from conception to deployment using only requirements expressed in language, images, video or audio? We explore this idea, building on the capabilities that Generative AI brings to software generation and maintenance techniques. How could designing software in this way better serve end-users? What are the implications of this process for the future of end-user software engineering and the software development lifecycle? We discuss the research needed to bridge the gap between where we are today and these imagined systems of the future.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = may,
articleno = {141},
numpages = {22},
keywords = {End-User Software Engineering, End-User Programming, Large Language Models},
annote={}
}

% Source 3 - Reflexive Prompt Engineering: A Framework for Responsible Prompt Engineering and AI Interaction Design
@inproceedings{10.1145/3715275.3732118,
author = {Djeffal, Christian},
title = {Reflexive Prompt Engineering: A Framework for Responsible Prompt Engineering and AI Interaction Design},
year = {2025},
isbn = {9798400714825},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3715275.3732118},
doi = {10.1145/3715275.3732118},
abstract = {Responsible prompt engineering has emerged as a critical pracitce for ensuring that generative artificial intelligence (AI) systems are aligned with ethical, legal, and social principles. As generative AI applications become increasingly powerful and ubiquitous, the way we instruct and interact with them through prompts has profound implications for fairness, accountability, and transparency. It is, therefore, necessary to examine how strategic prompt engineering can embed ethical and legal considerations and societal values directly into AI interactions, moving beyond mere technical optimization for functionality. This article proposes “Reflexive Prompt Engineering”, a comprehensive framework for responsible prompt engineering that encompasses five interconnected components: prompt design, system selection, system configuration, performance evaluation, and prompt management. Drawing from empirical evidence, the paper demonstrates how each component can be leveraged to promote improved societal outcomes while mitigating potential risks. The analysis reveals that effective prompt engineering requires a delicate balance between technical precision and ethical consciousness, combining the systematic rigor and focus on functionality with the nuanced understanding of social impact. Through examination of emerging practices, this article illustrates how responsible prompt engineering serves as a crucial connection between AI development and deployment, enabling organizations to align AI outputs without modifying underlying model architectures. This approach links with broader “Responsibility by Design” principles, embedding ethical considerations directly into the implementation process rather than treating them as post-hoc additions. The article concludes by identifying key research directions and practical guidelines for advancing the field of responsible prompt engineering as an essential component of AI literacy.},
booktitle = {Proceedings of the 2025 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1757-1768},
numpages = {12},
keywords = {AI Ethics, AI Governance, AI alignment, Accountability, Human-AI Interaction, Prompt Engineering, Responsible AI},
location = {
},
series = {FAccT '25},
annote={}
}

% Source 4 - An Agentic Framework for Compliant, Ethical and Trustworthy GenAI Applications in Healthcare
@inproceedings{10.1145/3727166.3727191,
author = {Menezes, Veena Priscilla and Chowdhury, Mohammad Jabed Morshed and Mahmood, Abdun},
title = {An Agentic Framework for Compliant, Ethical and Trustworthy GenAI Applications in Healthcare},
year = {2025},
isbn = {9798400715075},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3727166.3727191},
doi = {10.1145/3727166.3727191},
abstract = {Recent progress in generative artificial intelligence (GenAI) has yielded significant advancements in healthcare, affecting radiology, medical imaging, drug development, patient diagnostics, and supply chain optimisation. These innovations promise more improved diagnoses and time-saving cost-effectiveness. However, GenAI’s rapid implementation poses significant challenges for meeting regulatory, ethical, and trustworthiness standards. These challenges include data privacy issues, reproducibility concerns, algorithmic bias in training data causing disparities in outcomes, and a lack of transparency and explainability. Unresolved, these issues could negatively affect the public’s confidence in and perception of GenAI systems. Addressing these challenges, international AI governance frameworks, including the EU AI Act and WHO guidelines, prioritize regulatory adherence, trustworthiness, and the explainability of healthcare AI systems. While such frameworks have expanded, a deficiency remains in translating policy into effective compliance mechanisms. We propose a Compliance Agentic Model (CAM) framework to help organizations comply with GenAI and machine learning (ML)-based solutions. The CAM framework establishes trustworthiness in GenAI applications used in healthcare, ensuring alignment with organizational values and ethical standards to enhance accountability and regulatory adherence.},
booktitle = {Proceedings of the 2025 Australasian Computer Science Week},
pages = {48-54},
numpages = {7},
keywords = {GenAI, Healthcare, Agentic AI, Compliance},
location = {
},
series = {ACSW '25},
annote={}
}

% Source 5 - INSYTE: A Classification Framework for Traditional to Agentic AI Systems
@article{10.1145/3760424,
author = {Porter, Zoe and Calinescu, Radu and Lim, Ernest and Hodge, Victoria and Ryan, Philippa and Burton, Simon and Habli, Ibrahim and Lawton, Tom and McDermid, John and Molloy, John and Monkhouse, Helen and Morgan, Phillip and Noordhof, Paul and Paterson, Colin and Standen, Isobel and Zou, Jie},
title = {INSYTE: A Classification Framework for Traditional to Agentic AI Systems},
year = {2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4665},
url = {https://doi.org/10.1145/3760424},
doi = {10.1145/3760424},
abstract = {Existing classification frameworks for artificial intelligence (AI) and autonomous systems are being outpaced by recent advancements in AI technologies. This limits their applicability to modern intelligent systems, particularly agentic AI systems (autonomous systems that leverage foundation models to achieve wide-ranging, multi-layered goals). To address this deficiency, we introduce INSYTE, a multi-faceted framework that supports the classification of AI systems ranging from traditional rule-based systems to cutting-edge embodied AI and agentic systems. To that end, INSYTE considers the essential characteristics of an AI system across eight key dimensions grouped into four categories: system design (underspecification and adaptiveness); functionality (breadth and depth); operating environment (diversity and dynamism); and independence from human operational control (intervention and oversight). Different AI systems (or versions of systems) yield different “patterns” on an eight-axis radar chart that INSYTE uses to provide an immediate visual summary of an AI system's overall capability, and a detailed representation of its individual characteristics. The INSYTE framework aligns with OECD's definition of deployed AI systems, which is becoming the standard definition used by legislators and developers worldwide.},
note = {Just Accepted},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = aug,
keywords = {AI system, AI-enabled system, autonomous system, artificial intelligence, agentic AI, taxonomy, classification framework},
annote={}
}
